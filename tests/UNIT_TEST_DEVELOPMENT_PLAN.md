# üìã Plan zur 100%igen Unit-Test-Neuentwicklung (Feature f√ºr Feature)

Basierend auf der Analyse der ChessEndgameTrainer-Codebase erstelle ich einen detaillierten Plan f√ºr die parallele Feature-basierte Unit-Test-Entwicklung.

## üéØ Identifizierte Haupt-Features f√ºr Unit-Test-Entwicklung

---

## **Subtask 1: Chess Engine & Evaluation Core**

* **Zust√§ndiger Subagent/Team:** Team Alpha
* **Feature-Scope:** Alle Unit-Tests f√ºr das Herzst√ºck der Anwendung: ScenarioEngine, Evaluation Service, und die zentrale Engine-Logik in `shared/lib/chess/ScenarioEngine/`. Dies umfasst die Engine-Instanziierung, Evaluation-Requests, Tablebase-Integration und Engine-State-Management.
* **Ziel:** Komplette Unit-Test-Suite f√ºr die Engine-Kernlogik mit 90%+ Abdeckung, die alle kritischen Pfade, Fehlerbehandlung und Performance-kritische Operationen abdeckt.

* **Schritte zur Ausf√ºhrung:**
    1. **Verst√§ndnis des Features:** Analysiere `ScenarioEngine/index.ts`, `evaluationService.ts`, `tablebaseService.ts` um Engine-Lifecycle, Evaluation-Workflows und Tablebase-Queries zu verstehen.
    2. **Design der Unit-Testf√§lle:** Plane Tests f√ºr Engine-Initialisierung, Evaluation-Requests, Error-Recovery, Memory-Management und verschiedene Stellungstypen.
    3. **Generierung der Unit-Tests:** Erstelle isolierte Tests mit Mocks f√ºr Worker-APIs, verwende sprechende Namen wie `should_evaluate_position_correctly_when_tablebase_available`.
    4. **Dokumentation:** Dokumentiere kritische Test-Szenarien und Mock-Strategien f√ºr Engine-Worker-Kommunikation.
    5. **Verifikation:** Stelle sicher, dass Tests deterministisch laufen und Engine-Memory-Leaks erkannt werden.

---

## **Subtask 2: Worker Communication & Message Handling**

* **Zust√§ndiger Subagent/Team:** Team Beta  
* **Feature-Scope:** Unit-Tests f√ºr die Worker-Kommunikation in `shared/lib/chess/engine/`: `messageHandler.ts`, `requestManager.ts`, `workerManager.ts`. Fokus auf asynchrone Kommunikation, Request-Response-Zyklen und Worker-Lifecycle-Management.
* **Ziel:** Robuste Tests f√ºr alle Worker-Interaktionen mit Mock-Worker-APIs, die Race-Conditions, Timeouts und Message-Protokoll-Fehler abfangen.

* **Schritte zur Ausf√ºhrung:**
    1. **Verst√§ndnis des Features:** Verstehe Worker-Message-Protokolle, Request-Queuing und Worker-Cleanup-Mechanismen.
    2. **Design der Unit-Testf√§lle:** Entwerfe Tests f√ºr Message-Handling, Request-Timeouts, Worker-Termination und Concurrent-Request-Management.
    3. **Generierung der Unit-Tests:** Erstelle Mock-Worker mit kontrollierbaren Message-Delays, teste Error-Recovery-Pfade.
    4. **Dokumentation:** Dokumentiere Mock-Worker-Setup und kritische Timing-Szenarien.
    5. **Verifikation:** Teste mit verschiedenen Message-Reihenfolgen und Worker-Fehlerzust√§nden.

---

## **Subtask 3: Evaluation System & Caching**

* **Zust√§ndiger Subagent/Team:** Team Gamma
* **Feature-Scope:** Unit-Tests f√ºr das Performance-kritische Evaluation-System: `shared/lib/chess/evaluation/` (`unifiedService.ts`, `ChessAwareCache.ts`, `EvaluationDeduplicator.ts`, `ParallelEvaluationService.ts`) sowie `shared/lib/cache/LRUCache.ts` und `EvaluationCache.ts`.
* **Ziel:** Hochperformante Tests f√ºr Caching-Algorithmen, Request-Deduplizierung und parallele Evaluation-Workflows mit Fokus auf Memory-Effizienz.

* **Schritte zur Ausf√ºhrung:**
    1. **Verst√§ndnis des Features:** Analysiere Cache-Strategien, LRU-Algorithmus, Request-Deduplizierung und Parallel-Processing-Logic.
    2. **Design der Unit-Testf√§lle:** Plane Tests f√ºr Cache-Hits/Misses, Memory-Limits, Parallel-Request-Handling und Cache-Eviction-Strategien.
    3. **Generierung der Unit-Tests:** Erstelle deterministische Tests f√ºr Cache-Verhalten, verwende bekannte FEN-Strings als Test-Data.
    4. **Dokumentation:** Dokumentiere Cache-Performance-Metriken und Memory-Profiling-Strategien in Tests.
    5. **Verifikation:** √úberpr√ºfe Memory-Usage und Cache-Hit-Raten mit verschiedenen Stellungs-Patterns.

---

## **Subtask 4: Custom Hooks & React Integration**

* **Zust√§ndiger Subagent/Team:** Team Delta
* **Feature-Scope:** Unit-Tests f√ºr alle React Hooks in `shared/hooks/`: `useChessGame.ts`, `useEvaluation.ts`, `useEngine.ts`, `useLocalStorage.ts`, `useDebounce.ts`, `useAnalysisData.ts`. Fokus auf Hook-Lifecycle, State-Updates und Performance-Optimierungen.
* **Ziel:** Vollst√§ndige Hook-Tests mit React Testing Library, die State-Transitions, Debouncing-Verhalten und Side-Effects korrekt validieren.

* **Schritte zur Ausf√ºhrung:**
    1. **Verst√§ndnis des Features:** Verstehe Hook-Dependencies, State-Management-Patterns und Performance-Optimierungen wie Debouncing.
    2. **Design der Unit-Testf√§lle:** Entwerfe Tests f√ºr Hook-Mounting, State-Changes, Cleanup-Functions und Custom-Hook-Interactions.
    3. **Generierung der Unit-Tests:** Nutze `@testing-library/react-hooks`, teste Debouncing-Timing und localStorage-Integration.
    4. **Dokumentation:** Dokumentiere Hook-Usage-Patterns und Performance-Considerations.
    5. **Verifikation:** Teste Hook-Behavior mit verschiedenen Re-Render-Szenarien und Dependency-Changes.

---

## **Subtask 5: Chess Logic & Validation**

* **Zust√§ndiger Subagent/Team:** Team Epsilon
* **Feature-Scope:** Unit-Tests f√ºr die Kern-Schachlogik: `shared/lib/chess/stockfish.ts`, `tablebase.ts`, `validation.ts`, `mistakeCheck.ts`, `successCriteria.ts` sowie Chess-Utilities in `shared/utils/chess/`.
* **Ziel:** Umfassende Tests f√ºr Schachregeln, FEN-Validierung, Tablebase-Queries und Zugqualit√§ts-Bewertung mit Edge-Cases und Grenzwert-Szenarien.

* **Schritte zur Ausf√ºhrung:**
    1. **Verst√§ndnis des Features:** Analysiere Chess.js-Integration, FEN-String-Handling, Tablebase-API-Calls und Zugvalidierung.
    2. **Design der Unit-Testf√§lle:** Plane Tests f√ºr legale/illegale Z√ºge, FEN-Parsing-Errors, Tablebase-Timeouts und Edge-Case-Stellungen.
    3. **Generierung der Unit-Tests:** Verwende bekannte Chess-Stellungen als Test-Data, mocke Tablebase-APIs f√ºr deterministische Results.
    4. **Dokumentation:** Dokumentiere Chess-Position-Samples und Tablebase-Response-Formats.
    5. **Verifikation:** Teste mit komplexen Endspiel-Stellungen und invaliden FEN-Strings.

---

## **Subtask 6: Services & Error Handling**

* **Zust√§ndiger Subagent/Team:** Team Zeta
* **Feature-Scope:** Unit-Tests f√ºr alle Services in `shared/services/`: `errorService.ts`, `chess/EngineService.ts`, `logging/Logger.ts`, `platform/PlatformService.ts` und Mistake Analysis Services. Fokus auf Error-Recovery, Logging und Platform-Abstractions.
* **Ziel:** Robuste Tests f√ºr Service-Layer mit umfassender Error-Handling-Abdeckung und Platform-Compatibility-Tests.

* **Schritte zur Ausf√ºhrung:**
    1. **Verst√§ndnis des Features:** Verstehe Service-Architectures, Error-Propagation, Logging-Strategien und Platform-Specific-Code.
    2. **Design der Unit-Testf√§lle:** Entwerfe Tests f√ºr Service-Errors, Logger-Output, Platform-Detection und Cross-Platform-Compatibility.
    3. **Generierung der Unit-Tests:** Erstelle Mocks f√ºr Platform-APIs, teste Error-Logging und Service-Recovery-Mechanisms.
    4. **Dokumentation:** Dokumentiere Error-Scenarios und Platform-Specific-Considerations.
    5. **Verifikation:** Teste Service-Behavior unter verschiedenen Error-Conditions und Platform-Environments.

---

## **Subtask 7: Data Layer & Training System**

* **Zust√§ndiger Subagent/Team:** Team Eta
* **Feature-Scope:** Unit-Tests f√ºr `shared/data/endgames/`, Training Components in `shared/lib/training/spacedRepetition.ts` und Training Hooks. Fokus auf Datenintegrit√§t, Spaced-Repetition-Algorithmen und Training-State-Management.
* **Ziel:** Validiere alle Endspiel-Daten, teste Spaced-Repetition-Logic und Training-Progress-Tracking mit verschiedenen Lern-Szenarien.

* **Schritte zur Ausf√ºhrung:**
    1. **Verst√§ndnis des Features:** Analysiere Endspiel-Data-Structures, Spaced-Repetition-Algorithmus und Training-Progress-Logic.
    2. **Design der Unit-Testf√§lle:** Plane Tests f√ºr Data-Validation, Algorithm-Correctness und Training-State-Persistence.
    3. **Generierung der Unit-Tests:** Teste verschiedene Learning-Curves, Data-Corruption-Scenarios und Algorithm-Edge-Cases.
    4. **Dokumentation:** Dokumentiere Training-Algorithm-Parameters und Expected-Learning-Outcomes.
    5. **Verifikation:** Validiere Algorithm-Behavior mit verschiedenen User-Performance-Patterns.

---

# ü§ù Koordination & Konfliktvermeidung zwischen Subagenten

## **1. Klare Feature-Grenzen**
- Jedes Team arbeitet ausschlie√ülich in seinem zugewiesenen Feature-Bereich
- Feature-Ordner-Struktur: `tests/unit/[feature-name]/` (z.B. `tests/unit/engine/`, `tests/unit/evaluation/`)
- **Regel**: Kein Team darf Tests au√üerhalb seines Ordners erstellen oder modifizieren

## **2. Git-Branch-Strategie**
```bash
# Feature-Branch-Naming-Convention:
feature/unit-tests-[team-name]-[feature-name]
# Beispiele:
feature/unit-tests-alpha-engine-core
feature/unit-tests-beta-worker-communication
feature/unit-tests-gamma-evaluation-caching
```

## **3. Gemeinsame Test-Infrastruktur**
**Zentrale Test-Helpers** (getrennt entwickelt, vor Feature-Tests):
- `tests/helpers/mockFactories.ts` - Standard-Mock-Objekte 
- `tests/helpers/testData.ts` - Wiederverwendbare Chess-Stellungen
- `tests/helpers/engineMocks.ts` - Engine-Worker-Mocks
- `tests/helpers/cacheMocks.ts` - Cache-Test-Utilities

**Entwicklungsreihenfolge**:
1. **Woche 1**: Test-Helper-Bibliothek (gemeinsam)
2. **Woche 2-4**: Parallele Feature-Test-Entwicklung
3. **Woche 5**: Integration & Cross-Feature-Smoke-Tests

## **4. Qualit√§tssicherung**
- **Strict Code Review**: Alle Tests m√ºssen den Testing Guidelines entsprechen
- **Naming Convention Enforcement**: `describe('[FeatureName]')` ‚Üí `test('should_[behavior]_when_[condition]')`
- **Coverage Gates**: Minimum 85% Coverage pro Feature vor Merge
- **Documentation Standards**: Jeder Test-Block braucht Purpose-Kommentar

## **5. T√§gliche Synchronisation**
```markdown
**Daily Standup Template:**
- Gestern: Welche Tests wurden erstellt/fertiggestellt?
- Heute: Welcher Feature-Bereich wird bearbeitet?
- Blockers: Abh√§ngigkeiten zu anderen Teams?
- Shared Helpers: Neue Mock-Funktionen ben√∂tigt?
```

## **6. Definition of Done (DoD) f√ºr jeden Subtask**
- [ ] Alle Tests laufen gr√ºn (100% pass rate)
- [ ] Feature-Coverage ‚â• 85%
- [ ] Tests folgen Testing Guidelines (Checkliste erf√ºllt)
- [ ] Code Review approved (mindestens 1 anderes Team)
- [ ] Dokumentation vollst√§ndig (Test-Purpose in Kommentaren)
- [ ] Keine console.log oder Debug-Code in Tests
- [ ] Performance: Tests laufen in <5s pro Feature

**Merge-Kriterium**: Erst wenn DoD 100% erf√ºllt ist, darf der Feature-Branch gemerged werden.
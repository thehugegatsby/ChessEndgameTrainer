# ðŸ§ª Test-Guideline fÃ¼r den "Claude Build"

## ðŸŽ¯ Zweck dieser Richtlinie
Diese Guideline stellt sicher, dass alle neuen Tests im "Claude Build" konsistent, wartbar und effektiv sind. Eine robuste Testbasis ist entscheidend, um Fehler bei Upgrades zu vermeiden und das Vertrauen in unseren Code zu stÃ¤rken.

### ðŸ“Š Aktuelle Test-Metriken (Stand: 2025-07-07)
- **Test Coverage**: ~78% (Statement Coverage) - Ziel: 80%
- **Test Success**: 99% (787/796 tests passing, 9 skipped)
- **Neue Tests**: 128 Tests in Phase 2 hinzugefÃ¼gt
- **Kritische Bugs gefunden**: Perspective Transformation Bug durch Tests entdeckt
- **Error Handling**: âœ… Centralized ErrorService + Logger architecture implementiert

---

## ðŸ’¡ Grundprinzipien der Teststrategie

1.  **Testpyramide:** Wir streben eine ausgewogene Testpyramide an: Viele schnelle Unit-Tests, eine moderate Anzahl von Integrationstests und wenige, aber aussagekrÃ¤ftige End-to-End-Tests.
2.  **DRY (Don't Repeat Yourself):** Vermeide Code-Duplikation in Tests. Wiederverwendbare Test-Helfer und Fixtures sind erwÃ¼nscht.
3.  **KISS (Keep It Simple, Stupid):** Halte Tests so einfach und verstÃ¤ndlich wie mÃ¶glich. Jeder Test sollte einen einzigen Zweck verfolgen.
4.  **Testbarkeit:** Schreibe Code, der von Natur aus gut testbar ist. Achte auf lose Kopplung und klare Schnittstellen.
5.  **Regressionstests:** Jeder gefundene und behobene Fehler muss durch einen spezifischen, reproduzierbaren Test abgedeckt werden, der dauerhaft in die Testsuite integriert wird.
6.  âœ… **Was macht einen guten Test aus?**
    Nutze diese Checkliste beim Schreiben und Reviewen:
    - [ ] **PrÃ¼ft nur eine Sache** (Single Responsibility)
    - [ ] **LÃ¤sst sich in wenigen Sekunden lesen und verstehen**
    - [ ] **ErklÃ¤rt sich selbst** â€“ keine Kommentare notwendig
    - [ ] **FÃ¼hrt bei Fehlschlag zu einem hilfreichen Fehlerbericht**
    - [ ] **Verwendet sprechende Namen** fÃ¼r Test und Mocks
    - [ ] **Vermeidet Magische Werte** (z.â€¯B. `expect(x).toBe(42)` â†’ lieber: `expectedMoveCount = 42`)
    - [ ] **Ist unabhÃ¤ngig von AusfÃ¼hrungsreihenfolge**
    - [ ] **LÃ¤uft deterministisch** â€“ kein zufÃ¤lliges Verhalten

---

## ðŸ“ˆ Testtypen & Ihre Anwendung

### 1. Unit Tests (Komponente isoliert)

* **Zweck:** Testen der kleinsten isolierbaren Code-Einheit (z.B. eine Funktion, eine Klasse, ein Modul) in Isolation. Sie prÃ¼fen die interne Logik einer Komponente.
* **Eigenschaften:**
    * **Isoliert:** Keine realen AbhÃ¤ngigkeiten (Datenbank, externe APIs, andere komplexe Module). Nutze Mocks/Stubs, um AbhÃ¤ngigkeiten zu isolieren.
    * **Schnell:** MÃ¼ssen in Millisekunden laufen.
    * **Deterministisch:** FÃ¼hren immer zum gleichen Ergebnis.
* **Benennungs-Beispiel:** `[KomponentenName]_[Methode]_[Szenario]_[ErwartetesErgebnis]`
    * `ChessBoard_IsValidMove_KingCannotJumpOverPieces_ReturnsFalse`
    * `FenParser_Parse_ValidFenString_ReturnsCorrectBoardState`
* **Ablageort:** `tests/unit/[feature-area-oder-modulname]/`

### 2. Integration Tests (Komponenten-Interaktion)

* **Zweck:** Testen des Zusammenspiels mehrerer Komponenten oder Module, inklusive deren Interaktion mit realen (oder simulierten, aber realistischen) externen AbhÃ¤ngigkeiten.
* **Eigenschaften:**
    * **Fokus auf Schnittstellen:** PrÃ¼fen, ob die Kommunikation zwischen Modulen korrekt funktioniert.
    * **Realistische AbhÃ¤ngigkeiten:** KÃ¶nnen eine echte Datenbank, einen HTTP-Client oder einen Teil eines externen Dienstes (z.B. Tablebase-API-Aufruf) nutzen.
    * **Langsamer:** Laufen langsamer als Unit-Tests.
* **Benennungs-Beispiel:** `[Modul1]_[Modul2]Integration_[Szenario]_[ErwartetesErgebnis]`
    * `EvaluationApi_TablebaseIntegration_KnownEndgameFen_ReturnsCorrectTablebaseResult`
    * `MoveGenerator_BoardStateConverterIntegration_ComplexPosition_GeneratesAllLegalMoves`
* **Ablageort:** `tests/integration/[feature-area-oder-modulname]/`

### 3. End-to-End (E2E) Tests (Gesamter Benutzerfluss)

* **Zweck:** Testen des gesamten Systems aus Benutzersicht, vom initialen Input bis zur finalen Anzeige in der UI. Sie simulieren echte Benutzerinteraktionen.
* **Eigenschaften:**
    * **Systemweit:** Umfasst Frontend, Backend, Datenbank und alle Integrationen.
    * **Langsam:** Die langsamsten Tests, da sie das gesamte System hochfahren mÃ¼ssen.
    * **Hohes Vertrauen:** Geben das hÃ¶chste Vertrauen in die GesamtfunktionalitÃ¤t.
* **Benennungs-Beispiel:** `[BenutzerFlow]_[HauptSzenario]_[ErfolgsKriterium]`
    * `MoveEvaluationFullCycle_KingRookVsKing_CorrectlyDisplaysTablebaseResultAndBestMoves`
    * `UserAuthentication_LoginSuccess_DashboardDisplayed`
* **Ablageort:** `tests/e2e/[user-flow-oder-hauptszenario]/`

---

## ðŸ“ Test-Ordnerstruktur (Empfohlen)

Alle Testdateien sollten sich im `tests/`-Verzeichnis im Projekt-Root befinden und nach Testtyp und optional nach Feature-Bereich/Modul unterteilt sein:

[projekt-root]/
â””â”€â”€ tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ ChessEngine.test.js
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ FenParser.test.js
â”‚   â””â”€â”€ ...
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ evaluation-api/
â”‚   â”‚   â””â”€â”€ MoveEvaluationEndpoint.test.js
â”‚   â”œâ”€â”€ tablebase-service/
â”‚   â”‚   â””â”€â”€ TablebaseLookup.test.js
â”‚   â””â”€â”€ ...
â””â”€â”€ e2e/
â”œâ”€â”€ move-evaluation-flows/
â”‚   â””â”€â”€ EndgameBrandingTest.test.js
â”œâ”€â”€ user-authentication/
â”‚   â””â”€â”€ LoginProcess.test.js
â””â”€â”€ ...

Da ich keine Dateien direkt zum Herunterladen bereitstellen kann, gebe ich Ihnen den gesamten Inhalt der "Test Guideline" hier als **einen einzigen Textblock** aus.

Sie kÃ¶nnen diesen Text einfach kopieren und in einen Texteditor (wie Notepad, VS Code, Sublime Text oder TextEdit) einfÃ¼gen und dann als `test_guideline.md` speichern. So erhalten Sie eine fertige Markdown-Datei zum Herunterladen auf Ihrem GerÃ¤t.

-----

```markdown
# ðŸ§ª Test-Guideline fÃ¼r den "Claude Build"

## ðŸŽ¯ Zweck dieser Richtlinie
Diese Guideline stellt sicher, dass alle neuen Tests im "Claude Build" konsistent, wartbar und effektiv sind. Eine robuste Testbasis ist entscheidend, um Fehler bei Upgrades zu vermeiden und das Vertrauen in unseren Code zu stÃ¤rken.

### ðŸ“Š Aktuelle Test-Metriken (Stand: 2025-07-07)
- **Test Coverage**: ~78% (Statement Coverage) - Ziel: 80%
- **Test Success**: 99% (787/796 tests passing, 9 skipped)
- **Neue Tests**: 128 Tests in Phase 2 hinzugefÃ¼gt
- **Kritische Bugs gefunden**: Perspective Transformation Bug durch Tests entdeckt
- **Error Handling**: âœ… Centralized ErrorService + Logger architecture implementiert

---

## ðŸ’¡ Grundprinzipien der Teststrategie

1.  **Testpyramide:** Wir streben eine ausgewogene Testpyramide an: Viele schnelle Unit-Tests, eine moderate Anzahl von Integrationstests und wenige, aber aussagekrÃ¤ftige End-to-End-Tests.
2.  **DRY (Don't Repeat Yourself):** Vermeide Code-Duplikation in Tests. Wiederverwendbare Test-Helfer und Fixtures sind erwÃ¼nscht.
3.  **KISS (Keep It Simple, Stupid):** Halte Tests so einfach und verstÃ¤ndlich wie mÃ¶glich. Jeder Test sollte einen einzigen Zweck verfolgen.
4.  **Testbarkeit:** Schreibe Code, der von Natur aus gut testbar ist. Achte auf lose Kopplung und klare Schnittstellen.
5.  **Regressionstests:** Jeder gefundene und behobene Fehler muss durch einen spezifischen, reproduzierbaren Test abgedeckt werden, der dauerhaft in die Testsuite integriert wird.

---

## ðŸ“ˆ Testtypen & Ihre Anwendung

### 1. Unit Tests (Komponente isoliert)

* **Zweck:** Testen der kleinsten isolierbaren Code-Einheit (z.B. eine Funktion, eine Klasse, ein Modul) in Isolation. Sie prÃ¼fen die interne Logik einer Komponente.
* **Eigenschaften:**
    * **Isoliert:** Keine realen AbhÃ¤ngigkeiten (Datenbank, externe APIs, andere komplexe Module). Nutze Mocks/Stubs, um AbhÃ¤ngigkeiten zu isolieren.
    * **Schnell:** MÃ¼ssen in Millisekunden laufen.
    * **Deterministisch:** FÃ¼hren immer zum gleichen Ergebnis.
* **Benennungs-Beispiel:** `[KomponentenName]_[Methode]_[Szenario]_[ErwartetesErgebnis]`
    * `ChessBoard_IsValidMove_KingCannotJumpOverPieces_ReturnsFalse`
    * `FenParser_Parse_ValidFenString_ReturnsCorrectBoardState`
* **Ablageort:** `tests/unit/[feature-area-oder-modulname]/`

### 2. Integration Tests (Komponenten-Interaktion)

* **Zweck:** Testen des Zusammenspiels mehrerer Komponenten oder Module, inklusive deren Interaktion mit realen (oder simulierten, aber realistischen) externen AbhÃ¤ngigkeiten.
* **Eigenschaften:**
    * **Fokus auf Schnittstellen:** PrÃ¼fen, ob die Kommunikation zwischen Modulen korrekt funktioniert.
    * **Realistische AbhÃ¤ngigkeiten:** KÃ¶nnen eine echte Datenbank, einen HTTP-Client oder einen Teil eines externen Dienstes (z.B. Tablebase-API-Aufruf) nutzen.
    * **Langsamer:** Laufen langsamer als Unit-Tests.
* **Benennungs-Beispiel:** `[Modul1]_[Modul2]Integration_[Szenario]_[ErwartetesErgebnis]`
    * `EvaluationApi_TablebaseIntegration_KnownEndgameFen_ReturnsCorrectTablebaseResult`
    * `MoveGenerator_BoardStateConverterIntegration_ComplexPosition_GeneratesAllLegalMoves`
* **Ablageort:** `tests/integration/[feature-area-oder-modulname]/`

### 3. End-to-End (E2E) Tests (Gesamter Benutzerfluss)

* **Zweck:** Testen des gesamten Systems aus Benutzersicht, vom initialen Input bis zur finalen Anzeige in der UI. Sie simulieren echte Benutzerinteraktionen.
* **Eigenschaften:**
    * **Systemweit:** Umfasst Frontend, Backend, Datenbank und alle Integrationen.
    * **Langsam:** Die langsamsten Tests, da sie das gesamte System hochfahren mÃ¼ssen.
    * **Hohes Vertrauen:** Geben das hÃ¶chste Vertrauen in die GesamtfunktionalitÃ¤t.
* **Benennungs-Beispiel:** `[BenutzerFlow]_[HauptSzenario]_[ErfolgsKriterium]`
    * `MoveEvaluationFullCycle_KingRookVsKing_CorrectlyDisplaysTablebaseResultAndBestMoves`
    * `UserAuthentication_LoginSuccess_DashboardDisplayed`
* **Ablageort:** `tests/e2e/[user-flow-oder-hauptszenario]/`

---

## ðŸ“ Test-Ordnerstruktur (Empfohlen)

Alle Testdateien sollten sich im `tests/`-Verzeichnis im Projekt-Root befinden und nach Testtyp und optional nach Feature-Bereich/Modul unterteilt sein:

```

[projekt-root]/
â””â”€â”€ tests/
â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â””â”€â”€ ChessEngine.test.js
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ FenParser.test.js
â”‚   â””â”€â”€ ...
â”œâ”€â”€ integration/
â”‚   â”œâ”€â”€ evaluation-api/
â”‚   â”‚   â””â”€â”€ MoveEvaluationEndpoint.test.js
â”‚   â”œâ”€â”€ tablebase-service/
â”‚   â”‚   â””â”€â”€ TablebaseLookup.test.js
â”‚   â””â”€â”€ ...
â””â”€â”€ e2e/
â”œâ”€â”€ move-evaluation-flows/
â”‚   â””â”€â”€ EndgameBrandingTest.test.js
â”œâ”€â”€ user-authentication/
â”‚   â””â”€â”€ LoginProcess.test.js
â””â”€â”€ ...

```

---

## âš™ï¸ ZusÃ¤tzliche Richtlinien fÃ¼r neue Tests

1.  **Test-Driven Development (TDD):** Versuche, neue FunktionalitÃ¤t nach dem TDD-Prinzip zu entwickeln: Schreibe zuerst den (fehlgeschlagenen) Test, dann den Code, der den Test zum Bestehen bringt, und refaktoriere anschlieÃŸend.
2.  **Mocks & Stubs:**
    * **In Unit-Tests:** Verwende Mocks/Stubs, um externe AbhÃ¤ngigkeiten zu isolieren und die zu testende Einheit vollstÃ¤ndig zu kontrollieren.
    * **In Integration/E2E-Tests:** Vermeide Mocks, wenn eine reale Interaktion getestet werden soll. Setze sie nur ein, wenn eine externe Schnittstelle nicht kontrollierbar oder zu teuer ist.
3.  **Testdatenmanagement:**
    * Verwalte Testdaten explizit und versioniere sie (z.B. in separaten Dateien oder innerhalb der Testsuite).
    * FÃ¼r die **Zugbewertung**: Eine Datenbank mit kritischen FEN-Strings, ihren Tablebase-Bewertungen und erwarteten Engine-Bewertungen ist unerlÃ¤sslich.
4.  **Automatisierung (CI/CD):**
    * Alle Tests mÃ¼ssen Teil der automatisierten CI/CD-Pipeline sein.
    * Unit-Tests sollten bei jedem Push laufen. Integration- und E2E-Tests kÃ¶nnen in lÃ¤ngeren, aber regelmÃ¤ÃŸigen Zyklen laufen.
5.  **Code Coverage:** Strebe eine hohe Testabdeckung an (z.B. 80%+ fÃ¼r Unit-Tests in kritischen Modulen), aber fokussiere dich auf die QualitÃ¤t der Tests, nicht nur auf die Zahl.
6.  **Code Reviews:** Tests sind ein integraler Bestandteil des Code Reviews. PrÃ¼fe die TestqualitÃ¤t genauso wie die Code-QualitÃ¤t.

---

## â™Ÿï¸ DomÃ¤nen-Spezifische Tests (Fokus auf Schach-Bewertung - `o3 / ZEN MCP` Perspektive)

Besonders fÃ¼r die Zugbewertung ist PrÃ¤zision unerlÃ¤sslich:

### Evaluation Pipeline Tests
Die Evaluation Pipeline besteht aus mehreren unabhÃ¤ngigen Komponenten mit klarer Verantwortungstrennung:

* **PlayerPerspectiveTransformer Tests**:
  - Testet die korrekte Perspektiven-Transformation fÃ¼r Schwarz/WeiÃŸ
  - Verifiziert, dass Evaluierungen fÃ¼r Schwarz invertiert werden
  - Stellt sicher, dass WeiÃŸ-Perspektive unverÃ¤ndert bleibt
  
* **EvaluationDeduplicator Tests**:
  - Testet die Entfernung von Duplikaten in Evaluierungssequenzen
  - Verifiziert die Beibehaltung der richtigen Reihenfolge
  - PrÃ¼ft Edge Cases wie leere Arrays und einzelne Evaluierungen

* **ChessAwareCache Tests**:
  - Testet schachspezifische Cache-Optimierungen
  - Verifiziert Cache-Invalidierung bei MaterialÃ¤nderungen
  - PrÃ¼ft symmetrische Stellungserkennung
  - Testet LRU-Eviction bei Cache-Ãœberlauf

### Error Handling Tests
Mit der zentralisierten Error-Handling-Architektur sollten Tests folgende Patterns verwenden:

* **ErrorService Tests**:
  - Verifiziert korrekte Kategorisierung von Fehlern (Critical vs Non-Critical)
  - Testet User-Message Generation fÃ¼r verschiedene Fehlertypen
  - PrÃ¼ft Context-Daten Weiterleitung fÃ¼r Debugging
  - Validiert Error-Recovery Mechanismen

* **Logger Integration Tests**:
  - Testet strukturierte Log-Ausgabe mit Timestamps
  - Verifiziert Log-Level Konfiguration (DEBUG, INFO, WARN, ERROR)
  - PrÃ¼ft Platform-Context Injection in Log-Messages
  - Testet Log-Transport Konfiguration

* **Test Pattern fÃ¼r Error Handling**:
  ```typescript
  // Mocking fÃ¼r Error Tests
  const logger = getLogger();
  const loggerSpy = jest.spyOn(logger, 'warn').mockImplementation(() => {});
  
  // Error Service Testing
  const userMessage = ErrorService.handleChessEngineError(testError, {
    component: 'TestComponent',
    action: 'testAction',
    additionalData: { testData: 'value' }
  });
  
  expect(userMessage).toContain('Engine temporarily unavailable');
  expect(loggerSpy).toHaveBeenCalledWith(expect.stringContaining('ERROR'));
  ```

* **Tablebase-Validierung:** Teste explizit, ob bei Endspielen, die in Tablebases enthalten sind, **immer die exakten Tablebase-Ergebnisse** abgerufen und verwendet werden, und ob diese die Engine-SchÃ¤tzungen korrekt **Ã¼bersteuern**.
* **FEN-Szenarien:** Baue eine Test-Suite mit bekannten FEN-Positionen (z.B. Matt in N ZÃ¼gen, Remis-Stellungen, Gewinn-Stellungen) und verifiziere die **exakte numerische und qualitative Bewertung**.
* **Blunder- & Optimale-Zug-Verifikation:** Teste spezifische ZÃ¼ge, die bekannt gute oder bekannte fehlerhafte ZÃ¼ge sind, und verifiziere, dass sie mit den **korrekten Symbolen und Labels der Legende** angezeigt werden.
    * Beispiel: Der Blunder `Kb5` in der Stellung `2K5/2P2k2/8/8/4R3/8/1r6/8 w - - 0 1` muss mit `ðŸš¨` (Sieg â†’ Remis weggeworfen) visualisiert werden.
* **GrenzfÃ¤lle:** Teste Positionen, die Pattsituationen, Dauerschach, unmÃ¶gliche Stellungen oder andere Regelbesonderheiten beinhalten.

---
```